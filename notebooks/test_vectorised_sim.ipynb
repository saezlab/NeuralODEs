{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from nn_cno import ode\n",
    "import numpy as np\n",
    "import itertools\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import diffrax\n",
    "import optax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ode.logicODE(\"../nn_cno/datasets/working_case_study/PKN-test.sif\",\n",
    "    \"../nn_cno/datasets/working_case_study/MD-test.csv\")\n",
    "c.preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim  = c.simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = jnp.array(list(c.get_ODEparameters().values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.33 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "c.loss_function(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 µs ± 1.94 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "c.loss_function(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 1s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "c.loss_function_grad(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8 ms ± 88.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "c.loss_function_grad(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 0.1511961966753006\n",
      "\tparams: [1.0099999  2.01       0.09000007 1.         2.         0.10999993\n",
      " 0.99000007 1.9900001  0.99000007 1.9900001  0.10999993 1.0099999\n",
      " 2.0099998  1.         2.         0.09000007 1.         2.\n",
      " 0.09000007 1.         2.         0.10999993]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([1.0872488 , 2.0917668 , 0.06310978, 1.        , 2.        ,\n",
       "             0.18981409, 0.8983991 , 1.8984321 , 0.9014373 , 1.9042059 ,\n",
       "             0.19754875, 1.0726762 , 2.0754545 , 1.0003778 , 2.        ,\n",
       "             0.08042196, 1.        , 2.        , 0.00512886, 1.        ,\n",
       "             2.        , 0.19432251], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.fit(max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = np.zeros(params.shape)\n",
    "ub = np.ones(params.shape)\n",
    "dz = 0.1*np.ones(params.shape)\n",
    "\n",
    "def penalty_fn (x,lb,dz):\n",
    "    dept = (x-lb)/dz\n",
    "    p = 1e3*jnp.power(dept,2)\n",
    "    return(p)\n",
    "\n",
    "\n",
    "\n",
    "@jax.jit #@partial(jax.jit,static_argnums=(1,2,3))\n",
    "def penalty(params):\n",
    "\n",
    "    mse = jnp.where(params < lb+dz, 1, 0) * jnp.power((params-lb)/dz,2)*1e3\n",
    "    mse += jnp.where(params > ub-dz, 1, 0) * jnp.power((ub-params)/dz,2)*1e3\n",
    "    \n",
    "    return mse.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(800000., dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = jnp.array(list(c.get_ODEparameters().values()))\n",
    "penalty(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray(806000., dtype=float32),\n",
       " DeviceArray([     0., 200000.,  20000.,      0., 200000.,  20000.,\n",
       "                   0., 200000.,      0., 200000.,  20000.,      0.,\n",
       "              200000.,      0., 200000.,  20000.,      0., 200000.,\n",
       "               20000.,      0., 200000.,  20000.], dtype=float32))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.value_and_grad(penalty)(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = c.ODEparameters_lb.copy()\n",
    "ub = c.ODEparameters_ub.copy()\n",
    "dz = c.ODEparameters_dz.copy()\n",
    "\n",
    "@jax.jit\n",
    "def this_loss(params):\n",
    "    mse = 0.0\n",
    "    for i in range(len(params)):\n",
    "        if params[i] <= lb[i]+dz[i]:\n",
    "            dept = (params[i]-lb[i])/dz[i]\n",
    "            penalty = 1e3*jnp.power(dept,2)\n",
    "            mse += penalty\n",
    "            \n",
    "        elif params[i] > ub[i]-dz[i]:\n",
    "            dept = (ub[i] - params[i])/dz[i]\n",
    "            penalty = 1e3*jnp.power(dept,2)\n",
    "            mse += penalty\n",
    "\n",
    "    #params = jnp.clip(params, lb, ub)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22,)\n",
      "(22,)\n",
      "(22,)\n",
      "(22,)\n"
     ]
    }
   ],
   "source": [
    "print(lb.shape)\n",
    "print(ub.shape)\n",
    "print(dz.shape)\n",
    "print(params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConcretizationTypeError",
     "evalue": "Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(bool[])>with<DynamicJaxprTrace(level=0/1)>\nThe problem arose with the `bool` function. \nWhile tracing the function this_loss at /var/folders/cx/9kyr3rt90c974wdygym_lhgh0000gn/T/ipykernel_97931/2333120683.py:5 for jit, this concrete value was not available in Python because it depends on the value of the argument 'params'.\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConcretizationTypeError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/gabora/Documents/SaezGroup/LocalGitRepo/NN_cellnopt/NeuralODEs/notebooks/test_vectorised_sim.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gabora/Documents/SaezGroup/LocalGitRepo/NN_cellnopt/NeuralODEs/notebooks/test_vectorised_sim.ipynb#ch0000015?line=0'>1</a>\u001b[0m loss_value, grads \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mvalue_and_grad(this_loss)(params)\n",
      "    \u001b[0;31m[... skipping hidden 28 frame]\u001b[0m\n",
      "\u001b[1;32m/Users/gabora/Documents/SaezGroup/LocalGitRepo/NN_cellnopt/NeuralODEs/notebooks/test_vectorised_sim.ipynb Cell 17\u001b[0m in \u001b[0;36mthis_loss\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gabora/Documents/SaezGroup/LocalGitRepo/NN_cellnopt/NeuralODEs/notebooks/test_vectorised_sim.ipynb#ch0000015?line=6'>7</a>\u001b[0m mse \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gabora/Documents/SaezGroup/LocalGitRepo/NN_cellnopt/NeuralODEs/notebooks/test_vectorised_sim.ipynb#ch0000015?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(params)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gabora/Documents/SaezGroup/LocalGitRepo/NN_cellnopt/NeuralODEs/notebooks/test_vectorised_sim.ipynb#ch0000015?line=8'>9</a>\u001b[0m     \u001b[39mif\u001b[39;00m params[i] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m lb[i]\u001b[39m+\u001b[39mdz[i]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gabora/Documents/SaezGroup/LocalGitRepo/NN_cellnopt/NeuralODEs/notebooks/test_vectorised_sim.ipynb#ch0000015?line=9'>10</a>\u001b[0m         dept \u001b[39m=\u001b[39m (params[i]\u001b[39m-\u001b[39mlb[i])\u001b[39m/\u001b[39mdz[i]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gabora/Documents/SaezGroup/LocalGitRepo/NN_cellnopt/NeuralODEs/notebooks/test_vectorised_sim.ipynb#ch0000015?line=10'>11</a>\u001b[0m         penalty \u001b[39m=\u001b[39m \u001b[39m1e3\u001b[39m\u001b[39m*\u001b[39mjnp\u001b[39m.\u001b[39mpower(dept,\u001b[39m2\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/jax_ode/lib/python3.10/site-packages/jax/core.py:1171\u001b[0m, in \u001b[0;36mconcretization_function_error.<locals>.error\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merror\u001b[39m(\u001b[39mself\u001b[39m, arg):\n\u001b[0;32m-> 1171\u001b[0m   \u001b[39mraise\u001b[39;00m ConcretizationTypeError(arg, fname_context)\n",
      "\u001b[0;31mConcretizationTypeError\u001b[0m: Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(bool[])>with<DynamicJaxprTrace(level=0/1)>\nThe problem arose with the `bool` function. \nWhile tracing the function this_loss at /var/folders/cx/9kyr3rt90c974wdygym_lhgh0000gn/T/ipykernel_97931/2333120683.py:5 for jit, this concrete value was not available in Python because it depends on the value of the argument 'params'.\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError"
     ]
    }
   ],
   "source": [
    "loss_value, grads = jax.value_and_grad(this_loss)(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22,)\n",
      "(22,)\n",
      "(22,)\n",
      "(22,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lb.shape)\n",
    "print(ub.shape)\n",
    "print(dz.shape)\n",
    "print(params.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('jax_ode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bd868a791ae3f2e25c037fe0842082b59576b23b402251a9a0f392799515c5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

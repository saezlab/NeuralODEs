{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from nn_cno import ode\n",
    "import numpy as np\n",
    "import itertools\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import diffrax\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING [absl:335]: \u001b[0m \u001b[34mNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\u001b[0m\n",
      "\u001b[33mWARNING [absl:335]: \u001b[0m \u001b[34mNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\u001b[0m\n",
      "\u001b[33mWARNING [absl:335]: \u001b[0m \u001b[34mNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load the network \n",
    "c = ode.NNODE(\"../nn_cno/datasets/working_case_study/PKN-test.sif\",\n",
    "    \"../nn_cno/datasets/working_case_study/MD-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.preprocessing(expansion=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 48 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c.plot_simulation(c.simulate(stepsize_controller=diffrax.ConstantStepSize()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vmap for conditions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = jnp.array(list(c.get_ODEparameters().values()))\n",
    "sim_conditions = c.conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the gradient calculation through the multi-condition setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the gradient by central finite difference\n",
    "# evaluates the loss function at p and measured_data\n",
    "def cfd_grad_loss(model,p,dp=0.01):\n",
    "    \n",
    "    ref = p.copy()\n",
    "\n",
    "    grad = np.zeros((len(p),))\n",
    "\n",
    "    for i in range(len(p)):\n",
    "        p_working_p = np.array(ref)\n",
    "        p_working_n = np.array(ref)\n",
    "        p_working_p[i] += dp/2\n",
    "        p_working_n[i] -= dp/2\n",
    "        forward = model.loss_function(jnp.array(p_working_p))\n",
    "        backward = model.loss_function(jnp.array(p_working_n))\n",
    "        grad[i] = (forward - backward) / (dp)\n",
    "    return(grad)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = c.get_ODEparameters()\n",
    "jax_pars = jnp.asarray(list(pars.values()))\n",
    "grad = cfd_grad_loss(c,jax_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00836402, -0.00817031,  0.13481528,  0.        ,  0.        ,\n",
       "       -0.16944855,  0.00378191,  0.00368059,  0.00365376,  0.00328124,\n",
       "       -0.05428344, -0.0016287 , -0.00156462,  0.        ,  0.        ,\n",
       "        0.09228885,  0.        ,  0.        ,  0.18647909,  0.        ,\n",
       "        0.        , -0.06859154])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad\n",
    "\n",
    "#cfd_grad_loss(c,pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value, grads = jax.value_and_grad(c.loss_function)(jax_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-0.00836293, -0.00817067,  0.13509665,  0.        ,\n",
       "              0.        , -0.1691665 ,  0.00378179,  0.00368012,\n",
       "              0.00365477,  0.00328091, -0.05427588, -0.00162955,\n",
       "             -0.00156496,  0.        ,  0.        ,  0.09245268,\n",
       "              0.        ,  0.        ,  0.18656486,  0.        ,\n",
       "              0.        , -0.06858799], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([1.3085162e-04, 4.3997643e-05, 2.0827947e-03, 0.0000000e+00,\n",
       "             0.0000000e+00, 1.6672872e-03, 3.4107652e-05, 1.2590113e-04,\n",
       "             2.7482683e-04, 9.9563993e-05, 1.3933147e-04, 5.2236789e-04,\n",
       "             2.1416406e-04, 0.0000000e+00, 0.0000000e+00, 1.7720503e-03,\n",
       "             0.0000000e+00, 0.0000000e+00, 4.5973866e-04, 0.0000000e+00,\n",
       "             0.0000000e+00, 5.1706953e-05], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(grad- grads) / (abs(grads)+1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Parameter 1 is close to the lower boundary. Adding penalty Traced<ConcreteArray(-0.019352642819285393, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = DeviceArray(-0.01935264, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x17d979840>, in_tracers=(Traced<ConcreteArray(1.0003745555877686, dtype=float32):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=1/0)>), out_tracer_refs=[<weakref at 0x171010770; to 'JaxprTracer' at 0x1714a09f0>], out_avals=[ShapedArray(float32[])], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'jvp(<lambda>)', 'donated_invars': (False, False), 'inline': True, 'keep_unused': False, 'call_jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m b\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[]\u001b[39m = mul b a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x18c186030>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.17338376, dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.ODEparameters\n",
    "loss_value, grads = jax.value_and_grad(c.loss_function)(jax_pars.at[1].set(0.01))\n",
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 0.1511961668729782\n",
      "\tparams: [1.0099999  2.01       0.09000007 1.         2.         0.10999993\n",
      " 0.99000007 1.9900001  0.99000007 1.9900001  0.10999993 1.0099999\n",
      " 2.0099998  1.         2.         0.09000007 1.         2.\n",
      " 0.09000007 1.         2.         0.10999993]\n",
      "step 1, loss: 0.1443222314119339\n",
      "\tparams: [1.019936   2.019971   0.08009689 1.         2.         0.11989882\n",
      " 0.979988   1.9799896  0.9800056  1.9800311  0.11998016 1.0197117\n",
      " 2.0197775  1.         2.         0.08025719 1.         2.\n",
      " 0.08002293 1.         2.         0.11995059]\n",
      "step 2, loss: 0.13863182067871094\n",
      "\tparams: [1.0297452  2.0298805  0.07051601 1.         2.         0.12963502\n",
      " 0.969953   1.9699576  0.970037   1.9701341  0.12991285 1.0289009\n",
      " 2.0291333  0.99999464 2.         0.07134059 1.         2.\n",
      " 0.07009028 1.         2.         0.12980066]\n",
      "step 3, loss: 0.13425719738006592\n",
      "\tparams: [1.0393459  2.0396824  0.06185306 1.         2.         0.13915445\n",
      " 0.95988685 1.9598932  0.9601241  1.960358   0.13976403 1.0373769\n",
      " 2.0378816  1.0000213  2.         0.06448726 1.         2.\n",
      " 0.06022992 1.         2.         0.13949409]\n",
      "step 4, loss: 0.13116560876369476\n",
      "\tparams: [1.0486392  2.0493119  0.05537016 1.         2.         0.14841183\n",
      " 0.949784   1.949788   0.95029014 1.9507395  0.14950953 1.0450488\n",
      " 2.0459073  1.0000207  2.         0.06111026 1.         2.\n",
      " 0.05047679 1.         2.         0.14899084]\n",
      "step 5, loss: 0.12890280783176422\n",
      "\tparams: [1.0575205  2.0586903  0.05231715 1.         2.         0.15737128\n",
      " 0.93963677 1.9396348  0.94052833 1.9412779  0.15915696 1.0519208\n",
      " 2.0531797  1.0000104  2.         0.06126085 1.         2.\n",
      " 0.04087114 1.         2.         0.15829088]\n",
      "step 6, loss: 0.12672783434391022\n",
      "\tparams: [1.0658937  2.0677304  0.05248148 1.         2.         0.16600609\n",
      " 0.9294341  1.9294271  0.9308027  1.9319378  0.16874316 1.0580456\n",
      " 2.059719   1.0000254  2.         0.06400081 1.         2.\n",
      " 0.03145694 1.         2.         0.16742943]\n",
      "step 7, loss: 0.12426808476448059\n",
      "\tparams: [1.0736756  2.0763326  0.05487398 1.         2.         0.17429787\n",
      " 0.91916555 1.9191589  0.9210686  1.9226719  0.17831366 1.0634944\n",
      " 2.0655694  1.0000457  2.         0.06847011 1.         2.\n",
      " 0.02229219 1.         2.         0.17645414]\n",
      "step 8, loss: 0.12165114283561707\n",
      "\tparams: [1.0808032  2.084382   0.05863568 1.         2.         0.18223551\n",
      " 0.90882283 1.908827   0.91128844 1.9134378  0.18790704 1.0683452\n",
      " 2.0707905  1.000109   2.         0.07408059 1.         2.\n",
      " 0.01346876 1.         2.         0.18540817]\n",
      "step 9, loss: 0.11916252225637436\n",
      "\tparams: [1.0872488  2.0917668  0.06310979 1.         2.         0.18981409\n",
      " 0.8983991  1.8984321  0.9014373  1.9042059  0.19754875 1.0726762\n",
      " 2.0754545  1.0001131  2.         0.08042195 1.         2.\n",
      " 0.00512886 1.         2.         0.19432251]\n",
      "step 10, loss: 0.1170337125658989\n",
      "\tparams: [ 1.0930372   2.0984254   0.0677475   1.          2.          0.19703364\n",
      "  0.88788944  1.887982    0.8915032   1.8949609   0.20725027  1.0765575\n",
      "  2.0796342   1.0000834   2.          0.08717748  1.          2.\n",
      " -0.00253426  1.          2.          0.2032137 ]\n",
      "WARNING: Parameter 18 is close to the lower boundary. Adding penalty Traced<ConcreteArray(1.2386729717254639, dtype=float32)>with<JVPTrace(level=2/0)> with\n",
      "  primal = DeviceArray(1.238673, dtype=float32)\n",
      "  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=1/0)> with\n",
      "    pval = (ShapedArray(float32[]), None)\n",
      "    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x17d9797b0>, in_tracers=(Traced<ConcreteArray(2.534310817718506, dtype=float32):JaxprTrace(level=1/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=1/0)>), out_tracer_refs=[<weakref at 0x170f88e50; to 'JaxprTracer' at 0x170f8bf10>], out_avals=[ShapedArray(float32[])], primitive=xla_call, params={'device': None, 'backend': None, 'name': 'jvp(<lambda>)', 'donated_invars': (False, False), 'inline': True, 'keep_unused': False, 'call_jaxpr': { \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[]\u001b[39m b\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\u001b[39m\u001b[22m\u001b[22m c\u001b[35m:f32[]\u001b[39m = mul b a \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x18a54a130>, name_stack=NameStack(stack=(Transform(name='jvp'),))))\n",
      "step 11, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.20389827\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 12, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.21041511\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 13, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.21659367\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 14, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.22244513\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 15, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.2279819       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 16, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.23321715\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 17, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.23816451\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 18, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.24283782\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 19, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.24725088\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 20, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.2514174       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 21, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.25535077\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 22, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.25906405\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 23, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.26256987\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 24, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.26588044\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 25, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.26900738\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 26, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.27196193\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 27, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.27475473\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 28, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.27739593\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 29, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.27989513\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 30, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.28226146\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 31, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.28450352\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 32, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.28662944\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 33, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.2886469       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 34, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.2905631       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 35, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.29238483\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 36, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.29411846\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 37, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.29576993\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 38, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.29734486\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 39, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.29884848\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 40, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.30028567\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 41, loss: nan\n",
      "\tparams: [     nan      nan      nan 1.       2.       0.301661      nan      nan\n",
      "      nan      nan      nan      nan      nan      nan      nan      nan\n",
      "      nan      nan      nan      nan      nan      nan]\n",
      "step 42, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.30297878\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 43, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.30424297\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 44, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.30545726\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 45, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.30662513\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 46, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3077498       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 47, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.30883428\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 48, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.30988133\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 49, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.31089354\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 50, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.31187335\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 51, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.31282294\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 52, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.31374443\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 53, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.31463972\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 54, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3155106       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 55, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.31635872\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 56, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.31718558\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 57, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.31799263\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 58, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.31878117\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 59, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3195524       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 60, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.32030746\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 61, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3210474       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 62, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.32177314\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 63, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3224856       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 64, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.32318556\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 65, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.32387382\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 66, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.32455108\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 67, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.32521796\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 68, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.32587507\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 69, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.32652295\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 70, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.32716212\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 71, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.32779306\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 72, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3284162       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 73, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3290319       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 74, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3296406       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 75, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3302426       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 76, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.33083823\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 77, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.33142778\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 78, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.33201152\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 79, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3325897       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 80, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.33316255\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 81, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.33373028\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 82, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3342931       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 83, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.33485118\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 84, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3354047       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 85, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3359538       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 86, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.33649865\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 87, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.33703938\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 88, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3375761       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 89, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.33810893\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 90, loss: nan\n",
      "\tparams: [     nan      nan      nan 1.       2.       0.338638      nan      nan\n",
      "      nan      nan      nan      nan      nan      nan      nan      nan\n",
      "      nan      nan      nan      nan      nan      nan]\n",
      "step 91, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3391634       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 92, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3396852       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 93, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.34020352\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 94, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.34071845\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 95, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.34123006\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 96, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3417384       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n",
      "step 97, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.34224358\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 98, loss: nan\n",
      "\tparams: [       nan        nan        nan 1.         2.         0.34274563\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "step 99, loss: nan\n",
      "\tparams: [      nan       nan       nan 1.        2.        0.3432446       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan       nan       nan       nan       nan       nan       nan\n",
      "       nan]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([      nan,       nan,       nan, 1.       , 2.       ,\n",
       "             0.3432446,       nan,       nan,       nan,       nan,\n",
       "                   nan,       nan,       nan,       nan,       nan,\n",
       "                   nan,       nan,       nan,       nan,       nan,\n",
       "                   nan,       nan], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.fit(params=jax_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_params =  [ 1.0930372,   2.0984254,   0.0677475,   1. ,         2.,          0.19703364,\n",
    "  0.88788944,  1.887982,    0.8915032,   1.8949609,   0.20725027,  1.0765575,\n",
    "  2.0796342,   1.0000834,   2.,          0.08717748 , 1.,          2.,\n",
    " -0.00253426,  1. ,         2.,          0.2032137 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DeviceArray([[        nan,  0.        ,  0.        ,         nan,\n",
       "                0.        ,  0.        ,  1.        ,  0.        ],\n",
       "              [        nan,  0.        ,         nan,         nan,\n",
       "               -0.02566646,  0.8689262 ,  1.        ,  0.        ]],            dtype=float32, weak_type=True),\n",
       " DeviceArray([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "               0.        , 0.        , 1.        ],\n",
       "              [0.49209952, 0.860572  , 0.        , 0.5817866 , 0.        ,\n",
       "               0.        , 0.        , 1.        ]],            dtype=float32, weak_type=True),\n",
       " DeviceArray([[        nan,  0.        ,  0.        ,         nan,\n",
       "                0.        ,  0.        ,  1.        ,  1.        ],\n",
       "              [        nan,  0.860572  ,         nan,         nan,\n",
       "               -0.02566646,  0.8689262 ,  1.        ,  1.        ]],            dtype=float32, weak_type=True),\n",
       " DeviceArray([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "               0.        , 1.        , 0.        ],\n",
       "              [0.49209952, 0.        , 0.        , 0.        , 0.        ,\n",
       "               0.8689262 , 1.        , 0.        ]],            dtype=float32, weak_type=True),\n",
       " DeviceArray([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "               0.        , 1.        , 1.        ],\n",
       "              [0.49209952, 0.860572  , 0.24956195, 0.5817866 , 0.        ,\n",
       "               0.8689262 , 1.        , 1.        ]],            dtype=float32, weak_type=True),\n",
       " DeviceArray([[        nan,  0.        ,  0.        ,         nan,\n",
       "                0.        ,  0.        ,  1.        ,  0.        ],\n",
       "              [        nan,  0.        ,         nan,         nan,\n",
       "               -0.02566646,  0.        ,  1.        ,  0.        ]],            dtype=float32, weak_type=True)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l.ys for l in c.simulate(ODEparameters=jnp.asarray(my_params))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = optax.adam(learning_rate=1e-2)\n",
    "params = jax_pars.copy()\n",
    "opt_state = optimizer.init(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ScaleByAdamState(count=DeviceArray(0, dtype=int32), mu=DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "              0., 0., 0., 0., 0., 0., 0.], dtype=float32), nu=DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "              0., 0., 0., 0., 0., 0., 0.], dtype=float32)),\n",
       " EmptyState())"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15119617\n"
     ]
    }
   ],
   "source": [
    "loss_value, grads = jax.value_and_grad(c.loss_function)(params)\n",
    "print(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0099999  2.01       0.09000007 1.         2.         0.10999993\n",
      " 0.99000007 1.9900001  0.99000007 1.9900001  0.10999993 1.0099999\n",
      " 2.0099998  1.         2.         0.09000007 1.         2.\n",
      " 0.09000007 1.         2.         0.10999993]\n"
     ]
    }
   ],
   "source": [
    "updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "params = optax.apply_updates(params, updates)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tparams: [1.0099999  2.01       0.09000007 1.         2.         0.10999993\n",
      " 0.99000007 1.9900001  0.99000007 1.9900001  0.10999993 1.0099999\n",
      " 2.0099998  1.         2.         0.09000007 1.         2.\n",
      " 0.09000007 1.         2.         0.10999993]\n"
     ]
    }
   ],
   "source": [
    "print(f'\\tparams: {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ScaleByAdamState(count=DeviceArray(1, dtype=int32), mu=DeviceArray([-0.00083629, -0.00081707,  0.01350967,  0.        ,\n",
       "               0.        , -0.01691665,  0.00037818,  0.00036801,\n",
       "               0.00036548,  0.00032809, -0.00542759, -0.00016295,\n",
       "              -0.0001565 ,  0.        ,  0.        ,  0.00924527,\n",
       "               0.        ,  0.        ,  0.01865649,  0.        ,\n",
       "               0.        , -0.0068588 ], dtype=float32), nu=DeviceArray([6.99385581e-08, 6.67597888e-08, 1.82511067e-05,\n",
       "              0.00000000e+00, 0.00000000e+00, 2.86173072e-05,\n",
       "              1.43019037e-08, 1.35433096e-08, 1.33573383e-08,\n",
       "              1.07643645e-08, 2.94587107e-06, 2.65542721e-09,\n",
       "              2.44909093e-09, 0.00000000e+00, 0.00000000e+00,\n",
       "              8.54749942e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "              3.48064495e-05, 0.00000000e+00, 0.00000000e+00,\n",
       "              4.70431223e-06], dtype=float32)),\n",
       " EmptyState())"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(-22877334., dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.tan(1*(jnp.pi/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = jnp.zeros((len(params),))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([1., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "             0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = k.at[0].set(1)\n",
    "k.at[1].set(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PI3K_k_AKT': 1.0,\n",
       " 'PI3K_n_AKT': 2.0,\n",
       " 'tau_AKT': 0.1,\n",
       " 'TNFa_k_C8': 1.0,\n",
       " 'TNFa_n_C8': 2.0,\n",
       " 'tau_C8': 0.1,\n",
       " 'NFkB_k_ERK': 1.0,\n",
       " 'NFkB_n_ERK': 2.0,\n",
       " 'Raf_k_ERK': 1.0,\n",
       " 'Raf_n_ERK': 2.0,\n",
       " 'tau_ERK': 0.1,\n",
       " 'PI3K_k_NFkB': 1.0,\n",
       " 'PI3K_n_NFkB': 2.0,\n",
       " 'TNFa_k_NFkB': 1.0,\n",
       " 'TNFa_n_NFkB': 2.0,\n",
       " 'tau_NFkB': 0.1,\n",
       " 'TGFa_k_PI3K': 1.0,\n",
       " 'TGFa_n_PI3K': 2.0,\n",
       " 'tau_PI3K': 0.1,\n",
       " 'TGFa_k_Raf': 1.0,\n",
       " 'TGFa_n_Raf': 2.0,\n",
       " 'tau_Raf': 0.1}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.ODEparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('jax_ode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bd868a791ae3f2e25c037fe0842082b59576b23b402251a9a0f392799515c5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
